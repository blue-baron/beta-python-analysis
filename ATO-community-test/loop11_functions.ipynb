{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for basic bar graph\n",
    "def grapher(df, cols, title, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='bar', legend=False, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    ax.set_xticklabels(list(plot_df[cols].index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for bar graph with error bars\n",
    "def grapher_errorbar(df, cols, title, cis, labels, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#9d9d9c','#074f5f','#42bac7']\n",
    "    ax = plot_df.plot(kind='bar', legend=False, color=colours, edgecolor = \"none\", rot = 0, yerr=cis)\n",
    "    ax.set_xticklabels(list(plot_df[cols].index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    if not(not labels):\n",
    "        ax.legend(labels,loc='best')\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for horizontal graph\n",
    "def grapher_horizontal(df, cols, title, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#9d9d9c','#074f5f','#42bac7']\n",
    "    ax = plot_df.plot(kind='barh', legend=False, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    ax.set_yticklabels(list(plot_df[cols].index))\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for bar graph with stacked data sets\n",
    "def grapher_stacked(df, cols, title, labels, cis, location):\n",
    "    plot_df = df[cols].unstack(level=1).sort_index(ascending=False)\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0, yerr=cis)\n",
    "    ax.set_xticklabels(list(plot_df.index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    ax.legend(labels)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grapher_errorbar_stacked(df, cols, title, cis, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0, yerr = cis)\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for bar graph with stacked data sets but no CIs\n",
    "def grapher_no_error(df, cols, title, location):\n",
    "    plot_df = df[cols].unstack(level=1).sort_index(ascending=False)\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c', '#d8b2d8', '#f47920']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    ax.set_xticklabels(list(plot_df.index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def grapher_stacked_CIS(df, cols, title, labels, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    #ax.set_xticklabels(list(plot_df[cols].index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for graphs with stacked data sets\n",
    "def grapher_stacked_N(df, cols, title, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    ax.set_xticklabels(list(plot_df[cols].index))\n",
    "    ax.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for graphs with stacked data sets\n",
    "def grapher_stacked_horizontal(df, cols, title, location):\n",
    "    plot_df = df[cols]#.unstack(level=1)\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='barh', legend=False, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    ax.set_yticklabels(list(plot_df[cols].index))\n",
    "    ax.set_title(title)\n",
    "    plt.savefig(location+title+\".svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for graphs with stacked data sets\n",
    "def grapher_stacked_labels(df, cols, labels, title, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c', '#d8b2d8', '#f47920']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    #ax.set_xticklabels(list(plot_df[cols].index))\n",
    "    ax.set_title(title)\n",
    "    plt.legend(labels, bbox_to_anchor=(1.05, 1), loc=2,  borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for graphs with stacked data sets\n",
    "def grapher_stacked_labels_horizontal(df, cols, labels, title, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c', '#d8b2d8', '#f47920']\n",
    "    ax = plot_df.plot(kind='barh', legend=True, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    #ax.set_xticklabels(list(plot_df[cols].index))\n",
    "    ax.set_title(title)\n",
    "    plt.legend(labels, bbox_to_anchor=(1.05, 1), loc=2,  borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for bar graph with stacked data sets\n",
    "def grapher_demo_breakdown(df, cols, title, labels, cis, location):\n",
    "    #plot_df = df[cols].unstack(level=1).sort_index(ascending=False)\n",
    "    plot_df = df[cols]\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c', '#ffffff', '#eeeeee']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0, yerr=cis)\n",
    "    ax.set_xticklabels(list(plot_df.index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    ax.legend(labels)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Likert questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def likert_results(df, questions, graph_type, file_location):\n",
    "    \n",
    "    results_compact = []\n",
    "    results_numerical = []\n",
    "    \n",
    "    # Convert to numerical data for calculation of mean and std dev.\n",
    "    # 1 = SD, 2 = D, 3 = N A/D, 4 = A, 5 = SA\n",
    "    for q in questions:\n",
    "        \n",
    "        temp = df[q].replace('Strongly agree', 5, regex=True)\n",
    "        temp = temp.replace('Agree', 4, regex=True)\n",
    "        temp = temp.replace('Neither agree nor disagree', 3, regex=True)\n",
    "        temp = temp.replace('Disagree', 2, regex=True)\n",
    "        temp = temp.replace('Strongly disagree', 1, regex=True)\n",
    "        temp = temp.replace('NaN', 3, regex=True)\n",
    "        results_numerical.append(pd.DataFrame(temp))\n",
    "    \n",
    "    # Concatenate the list into a DataFrame and use describe() to get the mean and std dev.\n",
    "    results_numerical = pd.concat(results_numerical, axis=1)\n",
    "    print(results_numerical.describe())\n",
    "    \n",
    "    # Compact standard Likert answers to three-point scale.\n",
    "    # Create a list with question value counts (both number counts and as a percentage of the total).\n",
    "    for q in questions:\n",
    "        temp = df[q].replace('Strongly agree', 'Agree', regex=True)\n",
    "        temp = temp.replace('Strongly disagree', 'Disagree', regex=True)\n",
    "        temp = temp.replace('NaN', 3, regex=True)\n",
    "        results_compact.append(pd.DataFrame(temp.value_counts()))\n",
    "        results_compact.append(pd.DataFrame(temp.value_counts(normalize=True)))\n",
    "    \n",
    "    # Concatenate the list DataFrames into a single DataFrame\n",
    "    results_compact = pd.concat(results_compact, axis=1)\n",
    "    \n",
    "    # Create column titles list ('N' and '&' column for each question).\n",
    "    column_titles = []\n",
    "    for q in questions:\n",
    "        column_titles.append(q + ' (N)')\n",
    "        column_titles.append(q + ' (%)')\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    results_compact.columns = column_titles\n",
    "    \n",
    "    # Sort dataframe rows\n",
    "    results_compact.sort_index(axis=0, ascending=True, inplace=True)\n",
    "       \n",
    "    # Print % total is for quality control. The total should be 1.0 if question was required.\n",
    "    for q in questions:    \n",
    "        total_count = results_compact[q + ' (%)'].sum(axis=0)\n",
    "        print('TOTAL %: '  + str(total_count) + ' (' + q + ')')\n",
    "    \n",
    "        title = q.replace('\"', '')\n",
    "        graph_type(results_compact, [q + ' (%)'], title, file_location)\n",
    "        \n",
    "    #return final DataFrame for use in grapher functions.\n",
    "    return results_compact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple choice - single answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def single_answer(df, questions, graph_type, file_location):\n",
    "    \n",
    "    results = {}\n",
    "    # Create a list with question value counts (both number counts and as a percentage of the total).\n",
    "    for q in questions:\n",
    "        \n",
    "        results[q] = []\n",
    "\n",
    "        results[q].append(pd.DataFrame(df[q].value_counts(dropna=True)))\n",
    "        results[q].append(pd.DataFrame(df[q].value_counts(normalize=True, dropna=True)))\n",
    "\n",
    "        # Concatenate the list DataFrames into a single DataFrame\n",
    "        results[q] = pd.concat(results[q], axis=1)\n",
    "    \n",
    "        # Create column titles list ('N' and '&' column for each question).\n",
    "        column_titles = []\n",
    "        column_titles.append(q + ' (N)')\n",
    "        column_titles.append(q + ' (%)')\n",
    "    \n",
    "        # Rename columns in the DataFrame.\n",
    "        results[q].columns = column_titles\n",
    "        \n",
    "             \n",
    "        # Print sample size, % total and graph for each question\n",
    "        # Note: % total is for quality control. The total should be 1.0 if question was required.\n",
    "        sample_size = results[q][q + ' (N)'].sum(axis=0)\n",
    "        print('SAMPLE SIZE: ' + str(sample_size) + ' (' + q + ')')\n",
    "        total_count = results[q][q + ' (%)'].sum(axis=0)\n",
    "        print('TOTAL %: '  + str(total_count) + ' (' + q + ')')\n",
    "        \n",
    "        # Sort dataframe rows\n",
    "        results[q].sort_index(axis=0, ascending=True, inplace=True)\n",
    "        \n",
    "        # Display the results DataFrame\n",
    "        display(results[q])\n",
    "        \n",
    "        # Graph the results\n",
    "        title = q.replace('\"', '')\n",
    "        title = title.replace('?', '')\n",
    "        title = (title[:100] + '...') if len(title) > 100 else title\n",
    "        graph_type(results[q], [q + ' (%)'], title, file_location)\n",
    "        \n",
    "    #return final DataFrames.\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for analysing single answer questions where the results need to be grouped.\n",
    "# Parameters :\n",
    "#      df - dataframe, e.g. clean_df\n",
    "#      questions - The question to be analysed. Takes a string in a list.\n",
    "#      graph_type: The graph to be used.\n",
    "#      group_scale: The scale to group the data by. Takes a list of integers.\n",
    "#      group_labels - list of strings, labels of the columns for the output of the stacked data. \n",
    "#      file_location - string, folder location for saving the graph.\n",
    "\n",
    "def single_answer_grouped(df, questions, graph_type, group_scale, group_labels, file_location):\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    # Create a list with question value counts (both number counts and as a percentage of the total).\n",
    "    for q in questions:\n",
    "               \n",
    "        results[q] = []\n",
    "        \n",
    "        # Group the data by the scale.\n",
    "        temp = pd.cut(df[q], bins=group_scale, right=False, labels = group_labels)\n",
    "        \n",
    "        results[q].append(pd.DataFrame(temp.value_counts(dropna=True)))\n",
    "        results[q].append(pd.DataFrame(temp.value_counts(normalize=True, dropna=True)))\n",
    "\n",
    "        # Concatenate the list DataFrames into a single DataFrame\n",
    "        results[q] = pd.concat(results[q], axis=1)\n",
    "    \n",
    "        # Create column titles list ('N' and '&' column for each question).\n",
    "        column_titles = []\n",
    "        column_titles.append(q + ' (N)')\n",
    "        column_titles.append(q + ' (%)')\n",
    "    \n",
    "        # Rename columns in the DataFrame.\n",
    "        results[q].columns = column_titles\n",
    "        \n",
    "        # Sort dataframe rows\n",
    "        results[q].sort_index(axis=0, ascending=True, inplace=True)\n",
    "        \n",
    "        # Display the results DataFrame\n",
    "        display(df[q].describe())\n",
    "        display(results[q])\n",
    "            \n",
    "        # Graph the results\n",
    "        title = q.replace('\"', '')\n",
    "        title = title.replace('?', '')\n",
    "        title = (title[:100] + '...') if len(title) > 100 else title\n",
    "        graph_type(results[q], [q + ' (%)'], title, file_location)\n",
    "        \n",
    "    #return final DataFrames.\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple choice - multiple answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multiple_answer(df, questions, graph_type, file_location):\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for q in questions:\n",
    "        # Get sample size before the answers are split up.\n",
    "        sample_size = len(df[q])\n",
    "        \n",
    "        # Replace NaN with 'Other'\n",
    "        # Remove rows with 'Other'. NOT an accurate reflection of how many participants selected other.\n",
    "        # Due to Loop11 data format.\n",
    "        temp = df[q].fillna('Other')\n",
    "        temp = temp[temp.str.contains('Other') == False]\n",
    "    \n",
    "        # Break up the strings with ',' as the delimiter\n",
    "        broken_down = [sub.split(\",\") for sub in temp]\n",
    "        reshaped_list = [item.strip() for sublist in broken_down  for item in sublist]\n",
    "        set(reshaped_list)\n",
    "        temp = pd.DataFrame(reshaped_list)\n",
    "    \n",
    "        # Tally the results in a list of DataFrames\n",
    "        results[q] = []\n",
    "    \n",
    "        results[q].append(pd.DataFrame(temp[0].value_counts()))\n",
    "        results[q].append(pd.DataFrame(temp[0].value_counts()/len(df)))\n",
    "    \n",
    "        # Concatenate the results list into one DataFrame\n",
    "        results[q] = pd.concat(results[q], axis=1)\n",
    "        results[q].columns = [q + ' (N)', q + ' (%)']\n",
    "    \n",
    "        # print sample size, total number of answers received and graph of the results\n",
    "        print('SAMPLE SIZE: ' + str(sample_size))\n",
    "        total_answers = results[q][q + ' (N)'].sum(axis=0)\n",
    "        print('NO. ANSWERS: ' + str(total_answers))\n",
    "        \n",
    "        # Sort dataframe rows\n",
    "        results[q].sort_index(axis=0, ascending=False, inplace=True)\n",
    "    \n",
    "        # Display the results DataFrame\n",
    "        display(results[q])\n",
    "        \n",
    "        # Graph the results\n",
    "        title = q.replace('\"', '')\n",
    "        title = title.replace('?', '')\n",
    "        title = (title[:100] + '...') if len(title) > 100 else title\n",
    "        graph_type(results[q], [q + ' (%)'], title, file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE THIS FUNCTION NEEDS TO BE CORRECTED SO THE CI CALCULATION WORKS\n",
    "def task_completion_rates_N(df, tasks, N, file_location):\n",
    " \n",
    "    results = {}\n",
    "\n",
    "    for t in tasks:\n",
    "        results[t] = []\n",
    "        results[t].append(pd.DataFrame(df[t].value_counts()))\n",
    "        results[t].append(pd.DataFrame(df[t].value_counts(normalize=True)))\n",
    "\n",
    "        results[t] = pd.concat(results[t], axis=1)\n",
    "        results[t].index.names = ['Task Result']\n",
    "   \n",
    "        # Create column titles list ('N' and '&' column for each question).\n",
    "        column_titles = []    \n",
    "        column_titles.append(t + ' (N)')\n",
    "        column_titles.append(t + ' (%)')\n",
    "        \n",
    "        # Rename columns in the DataFrame.\n",
    "        results[t].columns = column_titles\n",
    "       \n",
    "        results[t] = results[t].reindex(['success', 'fail', 'abandon'])\n",
    "        \n",
    "        # CALCULATE CONFIDENCE INTERVALS\n",
    "        Task_p = (results[t][t + ' (N)']['success'])/N\n",
    "\n",
    "        # CI_95 = 1.96 * SQRT((adjusted_p * (1 - adjusted_p))/adjusted_n)\n",
    "        Task_CI = 1.96 * np.sqrt(Task_p * (1 - Task_p)/N)\n",
    "\n",
    "        # Print confidence intervals for reference.\n",
    "        print('CONFIDENCE INTERVAL: ' ,t , Task_CI)\n",
    "    \n",
    "        # Display the results DataFrame\n",
    "        display(results[t])\n",
    "    \n",
    "        # Graph the results\n",
    "        title = t.replace('\"', '')\n",
    "        title = title.replace('?', '')\n",
    "        title = (title[:100] + '...') if len(title) > 100 else title\n",
    "        grapher_errorbar(results[t], [t + ' (%)'], title, [Task_CI, Task_CI, Task_CI], [], file_location)\n",
    "\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_completion_rates_adjusted_N(df, tasks, N, file_location):\n",
    "    # Create task results dataframe for all tasks.\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for t in tasks:\n",
    "        results[t] = []\n",
    "        results[t].append(pd.DataFrame(df[t].value_counts()))\n",
    "        results[t].append(pd.DataFrame(df[t].value_counts(normalize=True)))\n",
    "\n",
    "        results[t] = pd.concat(results[t], axis=1)\n",
    "        results[t].index.names = ['Task Result']\n",
    "   \n",
    "        # Create column titles list ('N' and '&' column for each question).\n",
    "        column_titles = []    \n",
    "        column_titles.append(t + ' (N)')\n",
    "        column_titles.append(t + ' (%)')\n",
    "        \n",
    "        # Rename columns in the DataFrame.\n",
    "        results[t].columns = column_titles\n",
    "       \n",
    "        results[t] = results[t].reindex(['success', 'fail', 'abandon'])\n",
    "        \n",
    "        # CALCULATE CONFIDENCE INTERVALS\n",
    "        # For small sample size adjustment\n",
    "        # Adjust the sample size, N\n",
    "        def adjust_n(N):\n",
    "            return N+(1.96**2)\n",
    "\n",
    "        # Adjust the proportion of successes, p\n",
    "        def adjust_p(p, N):\n",
    "              return (p+1.92)/(N+3.84)\n",
    "\n",
    "        Task_p = results[t][t + ' (N)']['success']\n",
    "\n",
    "        # CI_95 = 1.96 * SQRT((adjusted_p * (1 - adjusted_p))/adjusted_n)\n",
    "        Task_CI = 1.96 * np.sqrt((adjust_p(Task_p,N) * (1 - adjust_p(Task_p,N)))/adjust_n(N))\n",
    "\n",
    "        # Print confidence intervals for reference.\n",
    "        print('CONFIDENCE INTERVAL: ' ,t , Task_CI)\n",
    "    \n",
    "        # Display the results DataFrame\n",
    "        display(results[t])\n",
    "    \n",
    "        # Graph the results\n",
    "        title = t.replace('\"', '')\n",
    "        title = title.replace('?', '')\n",
    "        title = (title[:100] + '...') if len(title) > 100 else title\n",
    "        grapher_errorbar(results[t], [t + ' (%)'], title, [Task_CI, Task_CI, Task_CI], [], file_location)\n",
    "\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison - Task vs multiple choice - MULTIPLE answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_task_VS_multiple_adjusted_N(df, group_q, group_names, task, file_location):\n",
    "    \n",
    "    # Create dataframes of required groups and store in a dict. \n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in group_names:\n",
    "        answer_groups[item] = df[df[group_q].str.contains('(?i)'+item) == True]\n",
    "        answer_groups[item].name = item\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for item in answer_groups:\n",
    "        # Create a list with task value counts.\n",
    "        results[item] = []\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts()))\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts(normalize=True)))\n",
    "\n",
    "        results[item] = pd.concat(results[item], axis=1)\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results, axis=1) \n",
    "    \n",
    "    # Get column names and add 'N' or '%'\n",
    "    column_titles = []\n",
    "    for item in combined_results.columns.get_level_values(0):\n",
    "        column_titles.insert(0, item + ' (N)')\n",
    "        column_titles.insert(0, item + ' (%)')\n",
    "    \n",
    "    # remove duplicate column names from the list\n",
    "    column_titles2 = []\n",
    "    for i in column_titles:\n",
    "        if i not in column_titles2:\n",
    "            column_titles2.insert(0, i)\n",
    "    \n",
    "    graph_columns = []\n",
    "    for i in column_titles2:\n",
    "        if \"(N)\" not in i: \n",
    "            graph_columns.insert(0, i)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    combined_results.columns = column_titles2\n",
    "    combined_results.index.name = task\n",
    "\n",
    "    \n",
    "    display(combined_results)\n",
    "        \n",
    "    # CALCULATE CONFIDENCE INTERVALS\n",
    "    def adjust_n(N):\n",
    "        return N+(1.96**2)\n",
    "    # Adjust the proportion of successes, p\n",
    "    def adjust_p(p, N):\n",
    "        return (p+1.92)/(N+3.84)\n",
    "    \n",
    "    # List to store CI in\n",
    "    CIs = [] \n",
    "    for item in group_names:\n",
    "        group_N = len(answer_groups[item])\n",
    "        Task_p = combined_results[item + ' (N)']['success']\n",
    "\n",
    "        # CI_95 = 1.96 * SQRT((adjusted_p * (1 - adjusted_p))/adjusted_n)\n",
    "        Task_CI = 1.96 * np.sqrt((adjust_p(Task_p, group_N) * (1 - adjust_p(Task_p, group_N)))/adjust_n(group_N))\n",
    "\n",
    "        # Save CI in list.\n",
    "        CIs.append([Task_CI,Task_CI,Task_CI])\n",
    "        \n",
    "        \n",
    "        # Print confidence intervals for reference.\n",
    "        print('CONFIDENCE INTERVAL: ' ,item , Task_CI)\n",
    "      \n",
    "    grapher_stacked_CIS(combined_results, graph_columns, task, [], file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_task_VS_multiple_N(df, group_q, group_names, task, file_location):\n",
    "    \n",
    "    # Create dataframes of required groups and store in a dict. \n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in group_names:\n",
    "        answer_groups[item] = df[df[group_q].str.contains('(?i)'+item) == True]\n",
    "        answer_groups[item].name = item\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for item in answer_groups:\n",
    "        # Create a list with task value counts.\n",
    "        results[item] = []\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts()))\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts(normalize=True)))\n",
    "\n",
    "        results[item] = pd.concat(results[item], axis=1)\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results, axis=1) \n",
    "    \n",
    "    # Get column names and add 'N' or '%'\n",
    "    column_titles = []\n",
    "    for item in combined_results.columns.get_level_values(0):\n",
    "        column_titles.insert(0, item + ' (N)')\n",
    "        column_titles.insert(0, item + ' (%)')\n",
    "    \n",
    "    # remove duplicate column names from the list\n",
    "    column_titles2 = []\n",
    "    for i in column_titles:\n",
    "        if i not in column_titles2:\n",
    "            column_titles2.insert(0, i)\n",
    "    \n",
    "    graph_columns = []\n",
    "    for i in column_titles2:\n",
    "        if \"(N)\" not in i: \n",
    "            graph_columns.insert(0, i)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    combined_results.columns = column_titles2\n",
    "    combined_results.index.name = task\n",
    "\n",
    "    \n",
    "    display(combined_results)\n",
    "        \n",
    "    # CALCULATE CONFIDENCE INTERVALS\n",
    "    \n",
    "    # List to store CI in\n",
    "    CIs = [] \n",
    "    for item in group_names:\n",
    "        group_N = len(answer_groups[item])\n",
    "        Task_p = combined_results[item + ' (N)']['success']\n",
    "\n",
    "        # CI_95 = 1.96 * SQRT((adjusted_p * (1 - adjusted_p))/adjusted_n)\n",
    "        Task_CI = 1.96 * np.sqrt(Task_p * (1 - Task_p)/group_N)\n",
    "        \n",
    "        # CALCULATE CONFIDENCE INTERVALS\n",
    "        Task_p = (results[t][t + ' (N)']['success'])/N\n",
    "\n",
    "\n",
    "        # Save CI in list.\n",
    "        CIs.append([Task_CI,Task_CI,Task_CI])\n",
    "        \n",
    "        \n",
    "        # Print confidence intervals for reference.\n",
    "        print('CONFIDENCE INTERVAL: ' ,item , Task_CI)\n",
    "      \n",
    "    grapher_stacked_CIS(combined_results, graph_columns, task, [], file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare success rates between 2 or groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create resutls for ATO versus non-ATO per task\n",
    "def breakdown_task_rates(df, task, breakdown, col_names, title, labels, location):\n",
    "    \n",
    "    groups = df[breakdown].unique()\n",
    "    print(groups)\n",
    "    results = []\n",
    "    \n",
    "    results.append(pd.DataFrame(df[task].groupby(df[breakdown]).value_counts()))\n",
    "    results.append(pd.DataFrame(df[task].groupby(df[breakdown]).value_counts(normalize=True)))\n",
    "    results = pd.concat(results, axis=1)\n",
    "    results.index.names = col_names\n",
    "    results.columns = [task+' (N)', task+' (%)']\n",
    "    results = results.sort_index(ascending=False)\n",
    "    \n",
    "    # print\n",
    "    display(results)\n",
    "    \n",
    "    # Calculate 95% CIfor each task results per group\n",
    "    # CI = p_hat +- 1.96 * (sqrt((p_hat*(1-p_hat))/n))\n",
    "    cis=[]\n",
    "    for i in groups:\n",
    "        n = results[task + ' (N)'][i].sum()\n",
    "        p_hat = (results[task + ' (N)'][i,'success'])/n\n",
    "        cis.append(1.96 * (np.sqrt((p_hat * (1-p_hat))/n)))\n",
    "    \n",
    "    grapher_stacked(results, task+' (%)', title, labels, cis, location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare likert results between 2 or groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# break down likert scale questions by dividing up group \n",
    "def breakdown_likert_rates(df, task, breakdown, col_names, title, labels, location):\n",
    "    # Compact standard Likert answers to three-point scale.\n",
    "    cleaned = df[task].replace({'Very dissatisfied': 'Dissatisfied', 'Very satisfied': 'Satisfied',\n",
    "                'Strongly disagree': 'Disagree', 'Strongly agree': 'Agree'}, regex=True)\n",
    "\n",
    "    temp = pd.concat([cleaned, df[breakdown]], axis=1)\n",
    "\n",
    "    results = []\n",
    "    results.append(pd.DataFrame(temp[task].groupby(temp[breakdown]).value_counts()))\n",
    "    results.append(pd.DataFrame(temp[task].groupby(temp[breakdown]).value_counts(normalize=True)))\n",
    "    results = pd.concat(results, axis=1)\n",
    "    results.index.names = col_names\n",
    "    results.columns = [task+' (N)', task+' (%)']\n",
    "    results = results.sort_index(ascending=False)\n",
    "\n",
    "    display(results)\n",
    "\n",
    "    grapher_no_error(results, task+' (%)', title, labels, location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison - Task vs likert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef compare_task_VS_likert(df, task, question, labels, location):\\n    \\n    likert_compact = []\\n    \\n    # Compact standard Likert answers to three-point scale and save in a list.\\n    # Create a list with task value counts.\\n    likert_compact.append(pd.DataFrame(df[question].replace(\\n                {\\'Strongly disagree\\': \\'Disagree\\', \\'Strongly agree\\': \\'Agree\\'}, regex=True)))\\n    likert_compact.append(pd.DataFrame(df[task]))\\n\\n    # convert the flat list into dataframe columns \\n    combined_results = pd.concat(likert_compact , axis=1) \\n\\n    # Create DataFrame with the results grouped by task completion rate.\\n    combined_results_df = []\\n    \\n    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts()))\\n    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts(normalize=True)))\\n    \\n    combined_results_df = pd.concat(combined_results_df, axis=1)\\n    combined_results_df.index.names = [task + \\' : Result\\', question]\\n    combined_results_df.columns = [\\'(N)\\', \\'(%)\\']\\n    combined_results_df = combined_results_df.sort_index(ascending=False)\\n    \\n    display(combined_results_df)\\n    \\n    # Graph the results\\n    title = question.replace(\\'\"\\', \\'\\')\\n    title = title.replace(\\'?\\', \\'\\')\\n    title = (title[:100] + \\'...\\') if len(title) > 100 else title\\n    \\n    # Graph the results\\n    grapher_no_error(combined_results_df, \\'(%)\\', title, labels, location)\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def compare_task_VS_likert(df, task, question, labels, location):\n",
    "    \n",
    "    likert_compact = []\n",
    "    \n",
    "    # Compact standard Likert answers to three-point scale and save in a list.\n",
    "    # Create a list with task value counts.\n",
    "    likert_compact.append(pd.DataFrame(df[question].replace(\n",
    "                {'Strongly disagree': 'Disagree', 'Strongly agree': 'Agree'}, regex=True)))\n",
    "    likert_compact.append(pd.DataFrame(df[task]))\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(likert_compact , axis=1) \n",
    "\n",
    "    # Create DataFrame with the results grouped by task completion rate.\n",
    "    combined_results_df = []\n",
    "    \n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts()))\n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts(normalize=True)))\n",
    "    \n",
    "    combined_results_df = pd.concat(combined_results_df, axis=1)\n",
    "    combined_results_df.index.names = [task + ' : Result', question]\n",
    "    combined_results_df.columns = ['(N)', '(%)']\n",
    "    combined_results_df = combined_results_df.sort_index(ascending=False)\n",
    "    \n",
    "    display(combined_results_df)\n",
    "    \n",
    "    # Graph the results\n",
    "    title = question.replace('\"', '')\n",
    "    title = title.replace('?', '')\n",
    "    title = (title[:100] + '...') if len(title) > 100 else title\n",
    "    \n",
    "    # Graph the results\n",
    "    grapher_no_error(combined_results_df, '(%)', title, labels, location)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for comparison of task success to likert scale questions\n",
    "\n",
    "# Parameters :\n",
    "#      df - dataframe, e.g. clean_df\n",
    "#      task - string, name of the column in the dataframe with the task data\n",
    "#      question - string, name of the column in the dataframe with the likert question data\n",
    "#      location - string, folder location for saving the graph to\n",
    "#      scale - dictionary, the likert scale used\n",
    "\n",
    "def compare_task_VS_likert(df, task, question, location, scale):\n",
    "    \n",
    "    likert_compact = []\n",
    "    \n",
    "    # Compact standard Likert answers to three-point scale and save in a list.\n",
    "    # Create a list with task value counts.\n",
    "    likert_compact.append(pd.DataFrame(df[question].replace(\n",
    "                {'Strongly disagree': 'Disagree', 'Strongly agree': 'Agree'}, regex=True)))\n",
    "    likert_compact.append(pd.DataFrame(df[task]))\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(likert_compact , axis=1) \n",
    "\n",
    "    # Create DataFrame with the results grouped by task completion rate.\n",
    "    combined_results_df = []\n",
    "    \n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts()))\n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts(normalize=True)))\n",
    "    \n",
    "    combined_results_df = pd.concat(combined_results_df, axis=1)\n",
    "    combined_results_df.index.names = [task + ' : Result', question]\n",
    "    combined_results_df.columns = ['(N)', '(%)']\n",
    "    combined_results_df = combined_results_df.sort_index(ascending=False)\n",
    "    \n",
    "    display(combined_results_df)\n",
    "    \n",
    "    # Graph the results\n",
    "    t = task.replace('\"', '')\n",
    "    q = question.replace('\"', '')\n",
    "    q = q.replace('* ', '')\n",
    "    title = t + ' vs. ' + q\n",
    "    \n",
    "    # Graph the results\n",
    "    grapher_no_error(combined_results_df, '(%)', title, location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison - Task vs multiple choice - SINGLE answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef compare_task_VS_single(df, task, question, graph_type, file_location):\\n    \\n    likert_compact = []\\n    \\n    # Compact standard Likert answers to three-point scale and save in a list.\\n    # Create a list with task value counts.\\n    likert_compact.append(pd.DataFrame(df[question]))\\n    likert_compact.append(pd.DataFrame(df[task]))\\n\\n    # convert the flat list into dataframe columns \\n    combined_results = pd.concat(likert_compact , axis=1) \\n\\n    # Create DataFrame with the results grouped by task completion rate.\\n    combined_results_df = []\\n    \\n    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts()))\\n    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts(normalize=True)))\\n    \\n    combined_results_df = pd.concat(combined_results_df, axis=1)\\n    combined_results_df.index.names = [task + ' : Result', question]\\n    combined_results_df.columns = ['(N)', '(%)']\\n    combined_results_df = combined_results_df.sort_index(ascending=False)\\n    \\n    display(combined_results_df)\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def compare_task_VS_single(df, task, question, graph_type, file_location):\n",
    "    \n",
    "    likert_compact = []\n",
    "    \n",
    "    # Compact standard Likert answers to three-point scale and save in a list.\n",
    "    # Create a list with task value counts.\n",
    "    likert_compact.append(pd.DataFrame(df[question]))\n",
    "    likert_compact.append(pd.DataFrame(df[task]))\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(likert_compact , axis=1) \n",
    "\n",
    "    # Create DataFrame with the results grouped by task completion rate.\n",
    "    combined_results_df = []\n",
    "    \n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts()))\n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts(normalize=True)))\n",
    "    \n",
    "    combined_results_df = pd.concat(combined_results_df, axis=1)\n",
    "    combined_results_df.index.names = [task + ' : Result', question]\n",
    "    combined_results_df.columns = ['(N)', '(%)']\n",
    "    combined_results_df = combined_results_df.sort_index(ascending=False)\n",
    "    \n",
    "    display(combined_results_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for comparison of task success to single answer questions\n",
    "# Parameters :\n",
    "#      df - dataframe, e.g. clean_df\n",
    "#      task - string, name of the column in the dataframe with the task data\n",
    "#      question task - string, name of the column in the dataframe with the likert question data\n",
    "#      location - string, folder location for saving the graph to\n",
    "def compare_task_VS_single(df, task, question, file_location):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Create a list with task value counts.\n",
    "    results.append(pd.DataFrame(df[question]))\n",
    "    results.append(pd.DataFrame(df[task]))\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results , axis=1) \n",
    "\n",
    "    # Create DataFrame with the results grouped by task completion rate.\n",
    "    combined_results_df = []\n",
    "    \n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts()))\n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts(normalize=True)))\n",
    "    \n",
    "    combined_results_df = pd.concat(combined_results_df, axis=1)\n",
    "    combined_results_df.index.names = [task + ' : Result', question]\n",
    "    combined_results_df.columns = ['(N)', '(%)']\n",
    "    combined_results_df = combined_results_df.sort_index(ascending=False)\n",
    "    \n",
    "    display(combined_results_df)\n",
    "    \n",
    "    # Graph the results\n",
    "    t = task.replace('\"', '')\n",
    "    q = question.replace('\"', '')\n",
    "    q = q.replace('* ', '')\n",
    "    title = t + ' vs. ' + q\n",
    "    title = (title[:100] + '...') if len(title) > 100 else title\n",
    "    \n",
    "    # Graph the results\n",
    "    grapher_no_error(combined_results_df, '(%)', title, file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison - Likert vs multiple choice - SINGLE answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_likert_VS_single(df, likert, question, graph_type, file_location):\n",
    "    \n",
    "    results_compact = []\n",
    "    \n",
    "    # Compact standard Likert answers to three-point scale and save in a list.\n",
    "    # Create a list with task value counts.\n",
    "    results_compact.append(pd.DataFrame(df[likert].replace({'Strongly disagree': 'Disagree', 'Strongly agree': 'Agree'}, regex=True)))\n",
    "    results_compact.append(pd.DataFrame(df[question]))\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results_compact , axis=1) \n",
    "\n",
    "    # Add grouped results dataframes to a list.\n",
    "    combined_results_df = []\n",
    "    \n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[likert]).value_counts()))\n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[likert]).value_counts(normalize=True)))\n",
    "    \n",
    "    # Convert list of grouped results dataframes into one DataFrame\n",
    "    combined_results_df = pd.concat(combined_results_df, axis=1)\n",
    "    combined_results_df.index.names = [likert, question]\n",
    "    combined_results_df.columns = ['(N)', '(%)']\n",
    "    combined_results_df = combined_results_df.sort_index(ascending=False)\n",
    "    \n",
    "    display(combined_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likert vs multiple choice - MULTIPLE answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_likert_VS_multiple(df, group_q, group_names, task, file_location):\n",
    "    \n",
    "    temp = []\n",
    "    temp.append(pd.DataFrame(df[task].replace({'Strongly disagree': 'Disagree', 'Strongly agree': 'Agree'}, regex=True)))\n",
    "    temp.append(pd.DataFrame(df[group_q]))\n",
    "    \n",
    "    temp_df = pd.concat(temp, axis=1)\n",
    "    \n",
    "    # Create dataframes of required groups and store in a dict. \n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in group_names:\n",
    "        answer_groups[item] = temp_df[temp_df[group_q].str.contains('(?i)'+item) == True]\n",
    "        answer_groups[item].name = item\n",
    "    \n",
    "    results = {}   \n",
    "    \n",
    "    for item in answer_groups:\n",
    "        \n",
    "        # Create a list with task value counts.\n",
    "        results[item] = []\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts()))\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts(normalize=True)))\n",
    "\n",
    "        results[item] = pd.concat(results[item], axis=1)\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results, axis=1) \n",
    "    \n",
    "    # Get column names and add 'N' or '%'\n",
    "    column_titles = []\n",
    "    for item in combined_results.columns.get_level_values(0):\n",
    "        column_titles.insert(0, item + ' (N)')\n",
    "        column_titles.insert(0, item + ' (%)')\n",
    "    \n",
    "    # remove duplicate column names from the list\n",
    "    column_titles2 = []\n",
    "    for i in column_titles:\n",
    "        if i not in column_titles2:\n",
    "            column_titles2.insert(0, i)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    combined_results.columns = column_titles2\n",
    "    combined_results.index.name = task\n",
    "      \n",
    "    display(combined_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple choice: SINGLE answer vs MULTIPLE answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_multiple_VS_single(df, group_q, group_names, single_q, file_location):\n",
    "    \n",
    "    # Create dataframes of required groups and store in a dict. \n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in group_names:\n",
    "        answer_groups[item] = df[df[group_q].str.contains('(?i)'+item) == True]\n",
    "        answer_groups[item].name = item\n",
    "    \n",
    "    results = {}\n",
    "    column_titles = []\n",
    "    graph_columns = []\n",
    "    \n",
    "    for item in answer_groups:\n",
    "        # Create a list with single_q value counts.\n",
    "        results[item] = []\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][single_q].value_counts()))\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][single_q].value_counts(normalize=True)))\n",
    "\n",
    "        results[item] = pd.concat(results[item], axis=1)\n",
    "    \n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results, axis=1) \n",
    "    \n",
    "    # Get column names and add 'N' or '%'\n",
    "    column_titles = []\n",
    "    for item in combined_results.columns.get_level_values(0):\n",
    "        column_titles.insert(0, item + ' (N)')\n",
    "        column_titles.insert(0, item + ' (%)')\n",
    "    \n",
    "    # remove duplicate column names from the list\n",
    "    column_titles2 = []\n",
    "    for i in column_titles:\n",
    "        if i not in column_titles2:\n",
    "            column_titles2.insert(0, i)\n",
    "            \n",
    "    graph_columns = []\n",
    "    for i in column_titles2:\n",
    "        if \"(N)\" not in i: \n",
    "            graph_columns.insert(0, i)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    combined_results.columns = column_titles2\n",
    "    combined_results.index.name = single_q\n",
    "      \n",
    "    display(combined_results)\n",
    "    \n",
    "    grapher_stacked_N(combined_results, graph_columns, single_q, file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display other results (for relevant questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def other_responses(df, question):\n",
    "    responses = []\n",
    "\n",
    "    responses.append(pd.DataFrame(df[question]))\n",
    "    responses = pd.concat(responses, axis=1)\n",
    "    responses = responses[responses[question].notnull()]\n",
    "\n",
    "    print('NUMBER OF RESPONSES: ' , len(responses))\n",
    "    \n",
    "    for item in responses[question]:\n",
    "        display(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of dataframes for dividing multiple answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dataframes of required groups.\n",
    "def define_groups(df, question, groups):\n",
    "    \n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in groups:\n",
    "        answer_groups[item] = df[df[question].str.contains('(?i)'+item) == True]\n",
    "        answer_groups[item].name = item\n",
    "    \n",
    "    return answer_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Functions to compare one group with everyone else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull out one group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to pull out the required group.\n",
    "# Everyone else is placed in a 'General' group.\n",
    "# This function is used in the COMPARE...TWO_GROUPS functions.\n",
    "\n",
    "def pull_out_group(df, group_q, group_names):\n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in group_names:\n",
    "        answer_groups[item] = df[df[group_q].str.contains('(?i)'+item) == True]\n",
    "        answer_groups['General'] = df[df[group_q].str.contains('(?i)'+item) == False]\n",
    "        answer_groups[item].name = item\n",
    "             \n",
    "    sample_total = 0\n",
    "    for item in answer_groups:\n",
    "        print(item, 'sample size:', len(answer_groups[item]))\n",
    "        sample_total += len(answer_groups[item])\n",
    "        \n",
    "    print('TOTAL:', sample_total)\n",
    "    \n",
    "    return answer_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Task results for one group vs everyone else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to compare TASK RESULTS for ONE demographic group with everyone else.\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!\n",
    "# THIS FUNCTION IS PRINTING THE CONFIDENCE INTERVALS FOR EACH GROUP BUT NOT PRINTING THEM ON THE GRAPH CORRECTLY.\n",
    "# FIX THIS! \n",
    "# THE GRAPH CURRENTLY WANTS 3 CONFIDENCE INTERVALS (for success, fail, abandon) BUT THE CIS ARE CALCULATED BY GROUP.\n",
    "# !!!!!!!!!!!!!!!!!!\n",
    "\n",
    "# PARAMETERS\n",
    "# answer_groups: a list of the groups being compared. This can be created using the pull_out_group() function.\n",
    "# task: The task. Takes a string which is the column name.\n",
    "# file_location: relative pathway where the graph will be saved.\n",
    "\n",
    "\n",
    "def COMPARE_task_TWO_GROUPS(df, group_q, group_names, task, file_location):\n",
    "       \n",
    "    # Create dataframes for each group and place in a dict.\n",
    "    answer_groups = pull_out_group(df, group_q, group_names)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for item in answer_groups:\n",
    "        # Create a list with task value counts.\n",
    "        results[item] = []\n",
    "        \n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts()))\n",
    "        results[item].append(pd.DataFrame((answer_groups[item][task].value_counts(normalize=True))))\n",
    "\n",
    "        results[item] = pd.concat(results[item], axis=1)\n",
    "\n",
    "        \n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results, axis=1) \n",
    "    \n",
    "    # Get column names and add 'N' or '%'\n",
    "    column_titles = []\n",
    "    for item in combined_results.columns.get_level_values(0):\n",
    "        column_titles.insert(0, item + ' (N)')\n",
    "        column_titles.insert(0, item + ' (%)')\n",
    "    \n",
    "    # remove duplicate column names from the list\n",
    "    column_titles2 = []\n",
    "    for i in column_titles:\n",
    "        if i not in column_titles2:\n",
    "            column_titles2.insert(0, i)\n",
    "   \n",
    "    graph_columns = []\n",
    "    for i in column_titles2:\n",
    "        if \"(N)\" not in i: \n",
    "            graph_columns.insert(0, i)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    combined_results.columns = column_titles2\n",
    "    combined_results.index.name = task\n",
    "\n",
    "    display(combined_results)\n",
    "    \n",
    "    # Calculate 95% CI for each task results per group\n",
    "    # CI = p_hat +- 1.96 * (sqrt((p_hat*(1-p_hat))/n))\n",
    "    cis = []\n",
    "    cis_labels={}\n",
    "    \n",
    "    headers  = ['General'] + group_names\n",
    "    for i in headers:\n",
    "        n = combined_results[i + ' (N)'].sum()\n",
    "        p_hat = (combined_results[i + ' (N)']['success'])/n\n",
    "        cis_labels[i] =  1.96 * (np.sqrt((p_hat * (1-p_hat))/n))\n",
    "        cis.append(1.96 * (np.sqrt((p_hat * (1-p_hat))/n)))\n",
    "        \n",
    "    print('Confidence intervals:', cis)\n",
    "    \n",
    "    grapher_errorbar_stacked(combined_results, graph_columns, task, cis[0], file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare single answer question for one group vs everyone else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to compare a SINGLE ANSWER QUESTION for ONE demographic group with everyone else.\n",
    "\n",
    "# PARAMETERS\n",
    "# ----------------------\n",
    "# answer_groups: a list of the groups being compared. This can be created using the pull_out_group() function.\n",
    "# task: The task. Takes a string which is the column name.\n",
    "# graph-type: Takes a beta.grapher function. Options are grapher_stacked_N or grapher_stacked_horizontal.\n",
    "# file_location: relative pathway where the graph will be saved.\n",
    "# ----------------------\n",
    "\n",
    "\n",
    "def COMPARE_single_answer_TWO_GROUPS(df, group_q, group_names, question, graph_type, file_location):\n",
    "       \n",
    "    # Create dataframes for each group and place in a dict.\n",
    "    answer_groups = pull_out_group(df, group_q, group_names)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for item in answer_groups:\n",
    "        # Create a list with question value counts.\n",
    "        results[item] = []\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][question].value_counts()))\n",
    "        results[item].append(pd.DataFrame((answer_groups[item][question].value_counts(normalize=True))*100))\n",
    "\n",
    "        results[item] = pd.concat(results[item], axis=1)\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results, axis=1)\n",
    "    \n",
    "   \n",
    "    # Get column names and add 'N' or '%'\n",
    "    column_titles = []\n",
    "    for item in combined_results.columns.get_level_values(0):\n",
    "        column_titles.insert(0, item + ' (N)')\n",
    "        column_titles.insert(0, item + ' (%)')\n",
    "    \n",
    "    # remove duplicate column names from the list\n",
    "    column_titles2 = []\n",
    "    for i in column_titles:\n",
    "        if i not in column_titles2:\n",
    "            column_titles2.insert(0, i)\n",
    "   \n",
    "    graph_columns = []\n",
    "    for i in column_titles2:\n",
    "        if \"(N)\" not in i: \n",
    "            graph_columns.insert(0, i)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    combined_results.columns = column_titles2\n",
    "    combined_results.index.name = question\n",
    "\n",
    "    \n",
    "    display(combined_results)\n",
    "       \n",
    "    graph_type(combined_results, graph_columns, question, file_location)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare likert question for one group vs everyone else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMPARE the answers of two groups in a Likert scale question.\n",
    "\n",
    "# Parameters:\n",
    "# ----------------------\n",
    "# df: the dataframe.\n",
    "# group_q: the question the specific group will be pulled from.\n",
    "# group_names: The name of the group. Takes a list with a string (the group name).\n",
    "# question: The likert question to be analysed.\n",
    "# ----------------------\n",
    "\n",
    "\n",
    "def COMPARE_likert_TWO_GROUPS(df, group_q, group_names, question, file_location):\n",
    "    \n",
    "    # Create dataframes for each group and place in a dict.\n",
    "    answer_groups = pull_out_group(df, group_q, group_names)\n",
    "    \n",
    "    # Convert to pandas dataframes for each group and place in a results dict.\n",
    "    results = {}\n",
    "    \n",
    "    for group, item in answer_groups.items():\n",
    "        results[group] = []\n",
    "        results[group].append(pd.DataFrame(item))\n",
    "        results[group] = pd.concat(results[group], axis=1)\n",
    "    \n",
    "    # Variables for the final dataframe and graph.\n",
    "    results_compact = []\n",
    "    column_titles = []\n",
    "    graph_columns = []\n",
    "    graph_labels = []\n",
    "    \n",
    "    # Compact the likert scale questions and create data for graphing.\n",
    "    for group, item in results.items():\n",
    "        item[question] = item[question].replace(to_replace='Strongly agree', value='Agree', regex=True)\n",
    "        item[question] = item[question].replace(to_replace='Strongly disagree', value='Disagree', regex=True)\n",
    "\n",
    "        temp = item[question]\n",
    "        \n",
    "        results_compact.append(pd.DataFrame(temp.value_counts()))\n",
    "        results_compact.append(pd.DataFrame((temp.value_counts(normalize=True))*100))\n",
    "        \n",
    "        column_titles.append(group + ' ' + question + ' (N)')\n",
    "        column_titles.append(group + ' ' + question + ' (%)')\n",
    "        graph_columns.append(group + ' ' + question + ' (%)')\n",
    "        graph_labels.append(group + ' (%)')\n",
    "\n",
    "    # Concatenate the list DataFrames into a single DataFrame\n",
    "    results_compact = pd.concat(results_compact, axis=1)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    results_compact.columns = column_titles\n",
    "    display(results_compact)\n",
    "    \n",
    "    # Sort dataframe rows\n",
    "    results_compact.sort_index(axis=0, ascending=True, inplace=True)\n",
    "    \n",
    "    grapher_stacked_labels(results_compact, graph_columns, graph_labels, question, file_location)\n",
    "        \n",
    "    #return answer_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare multiple answer question for one group vs everyone else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to compare a MULTIPLE ANSWER QUESTION for TWO GROUPS.\n",
    "\n",
    "# Parameters:\n",
    "# ----------------------\n",
    "# df: the dataframe.\n",
    "# group_q: the question the specific group will be pulled from.\n",
    "# group_names: The name of the group. Takes a list with a string (the group name).\n",
    "# question: The likert question to be analysed.\n",
    "# ----------------------\n",
    "\n",
    "\n",
    "def COMPARE_multiple_answer_TWO_GROUPS(df, group_q, group_names, question, file_location): \n",
    "    \n",
    "    # Create dataframes for each group and place in a dict.\n",
    "    answer_groups = pull_out_group(df, group_q, group_names)\n",
    "    \n",
    "    # Convert to pandas dataframes for each group and place in a results dict.\n",
    "    results = {}\n",
    "    \n",
    "    for group, item in answer_groups.items():\n",
    "        results[group] = []\n",
    "        results[group].append(pd.DataFrame(item))\n",
    "        results[group] = pd.concat(results[group], axis=1)\n",
    "    \n",
    "    # Variables for the final dataframe and graph.\n",
    "    answers_split_out = {}\n",
    "    column_titles = []\n",
    "    graph_columns = []\n",
    "    graph_labels = []\n",
    "    \n",
    "    # Compact the likert scale questions and create data for graphing.\n",
    "    for group, item in results.items():\n",
    "        \n",
    "        # Replace NaN with 'Other'\n",
    "        # Remove rows with 'Other'. NOT an accurate reflection of how many participants selected other.\n",
    "        # Due to Loop11 data format.\n",
    "        temp = item[question].fillna('Other')\n",
    "        temp = temp[temp.str.contains('Other') == False]\n",
    "        \n",
    "        # Break up the strings with ',' as the delimiter\n",
    "        broken_down = [sub.split(\",\") for sub in temp]\n",
    "        reshaped_list = [item.strip() for sublist in broken_down for item in sublist]\n",
    "        set(reshaped_list)\n",
    "        temp = pd.DataFrame(reshaped_list)\n",
    "        \n",
    "        # Tally the results for each group in a dict of DataFrames\n",
    "        answers_split_out[group] = []\n",
    "        \n",
    "        answers_split_out[group].append(pd.DataFrame(temp[0].value_counts()))\n",
    "        answers_split_out[group].append((pd.DataFrame(temp[0].value_counts(normalize=True))*100))\n",
    "        answers_split_out[group] = pd.concat(answers_split_out[group], axis=1)\n",
    "        answers_split_out[group].columns = [group + question + ' (N)', group + question + ' (%)']\n",
    "        \n",
    "        #column_titles.append(group + question + ' (N)')\n",
    "        #column_titles.append(group + question + ' (%)')\n",
    "        graph_columns.append(group + question + ' (%)')\n",
    "        graph_labels.append(group + ' (%)')\n",
    "    \n",
    "    # Concatenate into one dataframe\n",
    "    temp_df = []\n",
    "    for group, item in answers_split_out.items():\n",
    "        temp_df.append(item)\n",
    "    \n",
    "    results_final = pd.concat(temp_df, axis=1) \n",
    "    \n",
    "    display(results_final)\n",
    "    \n",
    "    grapher_stacked_labels_horizontal(results_final, graph_columns, graph_labels, question, file_location)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
