{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for basic bar graph\n",
    "def grapher(df, cols, title, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='bar', legend=False, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    ax.set_xticklabels(list(plot_df[cols].index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for bar graph with error bars\n",
    "def grapher_errorbar(df, cols, title, cis, labels, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#9d9d9c','#074f5f','#42bac7']\n",
    "    ax = plot_df.plot(kind='bar', legend=False, color=colours, edgecolor = \"none\", rot = 0, yerr=cis)\n",
    "    ax.set_xticklabels(list(plot_df[cols].index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    if not(not labels):\n",
    "        ax.legend(labels,loc='best')\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for horizontal graph\n",
    "def grapher_horizontal(df, cols, title, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#9d9d9c','#074f5f','#42bac7']\n",
    "    ax = plot_df.plot(kind='barh', legend=False, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    ax.set_yticklabels(list(plot_df[cols].index))\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for bar graph with stacked data sets\n",
    "def grapher_stacked(df, cols, title, labels, cis, location):\n",
    "    plot_df = df[cols].unstack(level=1).sort_index(ascending=False)\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0, yerr=cis)\n",
    "    ax.set_xticklabels(list(plot_df.index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    ax.legend(labels)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for bar graph with stacked data sets but no CIs\n",
    "def grapher_no_error(df, cols, title, labels, location):\n",
    "    plot_df = df[cols].unstack(level=1).sort_index(ascending=False)\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    ax.set_xticklabels(list(plot_df.index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def grapher_stacked_CIS(df, cols, title, labels, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    #ax.set_xticklabels(list(plot_df[cols].index))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for graphs with stacked data sets\n",
    "def grapher_stacked_N(df, cols, title, location):\n",
    "    plot_df = df[cols]\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='bar', legend=True, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    ax.set_xticklabels(list(plot_df[cols].index))\n",
    "    ax.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(location+title+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for graphs with stacked data sets\n",
    "def grapher_stacked_horizontal(df, cols, title, location):\n",
    "    plot_df = df[cols]#.unstack(level=1)\n",
    "    colours=['#42bac7','#074f5f','#9d9d9c']\n",
    "    ax = plot_df.plot(kind='barh', legend=False, color=colours, edgecolor = \"none\", rot = 0)\n",
    "    ax.set_yticklabels(list(plot_df[cols].index))\n",
    "    ax.set_title(title)\n",
    "    plt.savefig(location+title+\".svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple question analysis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Likert questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def likert_results(df, questions, graph_type, file_location):\n",
    "    \n",
    "    results_compact = []\n",
    "    \n",
    "    # Compact standard Likert answers to three-point scale.\n",
    "    # Create a list with question value counts (both number counts and as a percentage of the total).\n",
    "    for q in questions:\n",
    "        temp = df[q].replace('Strongly agree', 'Agree', regex=True)\n",
    "        temp = temp.replace('Strongly disagree', 'Disagree', regex=True)\n",
    "        results_compact.append(pd.DataFrame(temp.value_counts()))\n",
    "        results_compact.append(pd.DataFrame(temp.value_counts(normalize=True)))\n",
    "    \n",
    "    # Concatenate the list DataFrames into a single DataFrame\n",
    "    results_compact = pd.concat(results_compact, axis=1)\n",
    "    \n",
    "    # Create column titles list ('N' and '&' column for each question).\n",
    "    column_titles = []\n",
    "    for q in questions:\n",
    "        column_titles.append(q + ' (N)')\n",
    "        column_titles.append(q + ' (%)')\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    results_compact.columns = column_titles\n",
    "    \n",
    "    # Sort dataframe rows\n",
    "    results_compact.sort_index(axis=0, ascending=True, inplace=True)\n",
    "       \n",
    "    # Print sample size, % total and graph for each question\n",
    "    # Note: % total is for quality control. The total should be 1.0 if question was required.\n",
    "    for q in questions:\n",
    "        sample_size = results_compact[q + ' (N)'].sum(axis=0)\n",
    "        print('SAMPLE SIZE: ' + str(sample_size) + ' (' + q + ')')\n",
    "    \n",
    "        total_count = results_compact[q + ' (%)'].sum(axis=0)\n",
    "        print('TOTAL %: '  + str(total_count) + ' (' + q + ')')\n",
    "    \n",
    "        title = q.replace('\"', '')\n",
    "        graph_type(results_compact, [q + ' (%)'], title, file_location)\n",
    "        \n",
    "    #return final DataFrame for use in grapher functions.\n",
    "    return results_compact\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple choice - single answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def single_answer(df, questions, graph_type, file_location):\n",
    "    \n",
    "    results = {}\n",
    "    # Create a list with question value counts (both number counts and as a percentage of the total).\n",
    "    for q in questions:\n",
    "        results[q] = []\n",
    "\n",
    "        results[q].append(pd.DataFrame(df[q].value_counts(dropna=True)))\n",
    "        results[q].append(pd.DataFrame(df[q].value_counts(normalize=True, dropna=True)))\n",
    "\n",
    "        # Concatenate the list DataFrames into a single DataFrame\n",
    "        results[q] = pd.concat(results[q], axis=1)\n",
    "    \n",
    "        # Create column titles list ('N' and '&' column for each question).\n",
    "        column_titles = []\n",
    "        column_titles.append(q + ' (N)')\n",
    "        column_titles.append(q + ' (%)')\n",
    "    \n",
    "        # Rename columns in the DataFrame.\n",
    "        results[q].columns = column_titles\n",
    "        \n",
    "             \n",
    "        # Print sample size, % total and graph for each question\n",
    "        # Note: % total is for quality control. The total should be 1.0 if question was required.\n",
    "        sample_size = results[q][q + ' (N)'].sum(axis=0)\n",
    "        print('SAMPLE SIZE: ' + str(sample_size) + ' (' + q + ')')\n",
    "        total_count = results[q][q + ' (%)'].sum(axis=0)\n",
    "        print('TOTAL %: '  + str(total_count) + ' (' + q + ')')\n",
    "        \n",
    "        # Sort dataframe rows\n",
    "        results[q].sort_index(axis=0, ascending=True, inplace=True)\n",
    "        \n",
    "        # Display the results DataFrame\n",
    "        display(results[q])\n",
    "        \n",
    "        # Graph the results\n",
    "        title = q.replace('\"', '')\n",
    "        title = title.replace('?', '')\n",
    "        title = (title[:100] + '...') if len(title) > 100 else title\n",
    "        graph_type(results[q], [q + ' (%)'], title, file_location)\n",
    "        \n",
    "    #return final DataFrames.\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple choice - multiple answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multiple_answer(df, questions, graph_type, file_location):\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for q in questions:\n",
    "        # Get sample size before the answers are split up.\n",
    "        sample_size = len(df[q])\n",
    "        \n",
    "        # Replace NaN with 'Other'\n",
    "        # Remove rows with 'Other'. NOT an accurate reflection of how many participants selected other.\n",
    "        # Due to Loop11 data format.\n",
    "        temp = df[q].fillna('Other')\n",
    "        temp = temp[temp.str.contains('Other') == False]\n",
    "    \n",
    "        # Break up the strings with ',' as the delimiter\n",
    "        broken_down = [sub.split(\",\") for sub in temp]\n",
    "        reshaped_list = [item.strip() for sublist in broken_down  for item in sublist]\n",
    "        set(reshaped_list)\n",
    "        temp = pd.DataFrame(reshaped_list)\n",
    "    \n",
    "        # Tally the results in a list of DataFrames\n",
    "        results[q] = []\n",
    "    \n",
    "        results[q].append(pd.DataFrame(temp[0].value_counts()))\n",
    "        results[q].append(pd.DataFrame(temp[0].value_counts()/len(df)))\n",
    "    \n",
    "        # Concatenate the results list into one DataFrame\n",
    "        results[q] = pd.concat(results[q], axis=1)\n",
    "        results[q].columns = [q + ' (N)', q + ' (%)']\n",
    "    \n",
    "        # print sample size, total number of answers received and graph of the results\n",
    "        print('SAMPLE SIZE: ' + str(sample_size))\n",
    "        total_answers = results[q][q + ' (N)'].sum(axis=0)\n",
    "        print('NO. ANSWERS: ' + str(total_answers))\n",
    "        \n",
    "        # Sort dataframe rows\n",
    "        results[q].sort_index(axis=0, ascending=True, inplace=True)\n",
    "    \n",
    "        # Display the results DataFrame\n",
    "        display(results[q])\n",
    "        \n",
    "        # Graph the results\n",
    "        title = q.replace('\"', '')\n",
    "        title = title.replace('?', '')\n",
    "        title = (title[:100] + '...') if len(title) > 100 else title\n",
    "        graph_type(results[q], [q + ' (%)'], title, file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE THIS FUNCTION NEEDS TO BE CORRECTED SO THE CI CALCULATION WORKS\n",
    "def task_completion_rates_N(df, tasks, N, file_location):\n",
    " \n",
    "    results = {}\n",
    "\n",
    "    for t in tasks:\n",
    "        results[t] = []\n",
    "        results[t].append(pd.DataFrame(df[t].value_counts()))\n",
    "        results[t].append(pd.DataFrame(df[t].value_counts(normalize=True)))\n",
    "\n",
    "        results[t] = pd.concat(results[t], axis=1)\n",
    "        results[t].index.names = ['Task Result']\n",
    "   \n",
    "        # Create column titles list ('N' and '&' column for each question).\n",
    "        column_titles = []    \n",
    "        column_titles.append(t + ' (N)')\n",
    "        column_titles.append(t + ' (%)')\n",
    "        \n",
    "        # Rename columns in the DataFrame.\n",
    "        results[t].columns = column_titles\n",
    "       \n",
    "        results[t] = results[t].reindex(['success', 'fail', 'abandon'])\n",
    "        \n",
    "        # CALCULATE CONFIDENCE INTERVALS\n",
    "        Task_p = (results[t][t + ' (N)']['success'])/N\n",
    "\n",
    "        # CI_95 = 1.96 * SQRT((adjusted_p * (1 - adjusted_p))/adjusted_n)\n",
    "        Task_CI = 1.96 * np.sqrt(Task_p * (1 - Task_p)/N)\n",
    "\n",
    "        # Print confidence intervals for reference.\n",
    "        print('CONFIDENCE INTERVAL: ' ,t , Task_CI)\n",
    "    \n",
    "        # Sort dataframe rows\n",
    "        results[t].sort_index(axis=0, ascending=True, inplace=True)\n",
    "        \n",
    "        # Display the results DataFrame\n",
    "        display(results[t])\n",
    "    \n",
    "        # Graph the results\n",
    "        title = t.replace('\"', '')\n",
    "        title = title.replace('?', '')\n",
    "        title = (title[:100] + '...') if len(title) > 100 else title\n",
    "        grapher_errorbar(results[t], [t + ' (%)'], title, [Task_CI, Task_CI, Task_CI], [], file_location)\n",
    "\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_completion_rates_adjusted_N(df, tasks, N, file_location):\n",
    "    # Create task results dataframe for all tasks.\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for t in tasks:\n",
    "        results[t] = []\n",
    "        results[t].append(pd.DataFrame(df[t].value_counts()))\n",
    "        results[t].append(pd.DataFrame(df[t].value_counts(normalize=True)))\n",
    "\n",
    "        results[t] = pd.concat(results[t], axis=1)\n",
    "        results[t].index.names = ['Task Result']\n",
    "   \n",
    "        # Create column titles list ('N' and '&' column for each question).\n",
    "        column_titles = []    \n",
    "        column_titles.append(t + ' (N)')\n",
    "        column_titles.append(t + ' (%)')\n",
    "        \n",
    "        # Rename columns in the DataFrame.\n",
    "        results[t].columns = column_titles\n",
    "       \n",
    "        results[t] = results[t].reindex(['success', 'fail', 'abandon'])\n",
    "        \n",
    "        # CALCULATE CONFIDENCE INTERVALS\n",
    "        # For small sample size adjustment\n",
    "        # Adjust the sample size, N\n",
    "        def adjust_n(N):\n",
    "            return N+(1.96**2)\n",
    "\n",
    "        # Adjust the proportion of successes, p\n",
    "        def adjust_p(p, N):\n",
    "              return (p+1.92)/(N+3.84)\n",
    "\n",
    "        Task_p = results[t][t + ' (N)']['success']\n",
    "\n",
    "        # CI_95 = 1.96 * SQRT((adjusted_p * (1 - adjusted_p))/adjusted_n)\n",
    "        Task_CI = 1.96 * np.sqrt((adjust_p(Task_p,N) * (1 - adjust_p(Task_p,N)))/adjust_n(N))\n",
    "\n",
    "        # Print confidence intervals for reference.\n",
    "        print('CONFIDENCE INTERVAL: ' ,t , Task_CI)\n",
    "    \n",
    "        # Sort dataframe rows\n",
    "        results[t].sort_index(axis=0, ascending=True, inplace=True)\n",
    "        \n",
    "        # Display the results DataFrame\n",
    "        display(results[t])\n",
    "    \n",
    "        # Graph the results\n",
    "        title = t.replace('\"', '')\n",
    "        title = title.replace('?', '')\n",
    "        title = (title[:100] + '...') if len(title) > 100 else title\n",
    "        grapher_errorbar(results[t], [t + ' (%)'], title, [Task_CI, Task_CI, Task_CI], [], file_location)\n",
    "\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question comparison functions \n",
    "### (compare one question with another)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison - Task vs multiple choice - MULTIPLE answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_task_VS_multiple_adjusted_N(df, group_q, group_names, task, file_location):\n",
    "    \n",
    "    # Create dataframes of required groups and store in a dict. \n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in group_names:\n",
    "        answer_groups[item] = df[df[group_q].str.contains('(?i)'+item) == True]\n",
    "        answer_groups[item].name = item\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for item in answer_groups:\n",
    "        # Create a list with task value counts.\n",
    "        results[item] = []\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts()))\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts(normalize=True)))\n",
    "\n",
    "        results[item] = pd.concat(results[item], axis=1)\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results, axis=1) \n",
    "    \n",
    "    # Get column names and add 'N' or '%'\n",
    "    column_titles = []\n",
    "    for item in combined_results.columns.get_level_values(0):\n",
    "        column_titles.insert(0, item + ' (N)')\n",
    "        column_titles.insert(0, item + ' (%)')\n",
    "    \n",
    "    # remove duplicate column names from the list\n",
    "    column_titles2 = []\n",
    "    for i in column_titles:\n",
    "        if i not in column_titles2:\n",
    "            column_titles2.insert(0, i)\n",
    "    \n",
    "    graph_columns = []\n",
    "    for i in column_titles2:\n",
    "        if \"(N)\" not in i: \n",
    "            graph_columns.insert(0, i)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    combined_results.columns = column_titles2\n",
    "    combined_results.index.name = task\n",
    "\n",
    "    \n",
    "    display(combined_results)\n",
    "        \n",
    "    # CALCULATE CONFIDENCE INTERVALS\n",
    "    def adjust_n(N):\n",
    "        return N+(1.96**2)\n",
    "    # Adjust the proportion of successes, p\n",
    "    def adjust_p(p, N):\n",
    "        return (p+1.92)/(N+3.84)\n",
    "    \n",
    "    # List to store CI in\n",
    "    CIs = [] \n",
    "    for item in group_names:\n",
    "        group_N = len(answer_groups[item])\n",
    "        Task_p = combined_results[item + ' (N)']['success']\n",
    "\n",
    "        # CI_95 = 1.96 * SQRT((adjusted_p * (1 - adjusted_p))/adjusted_n)\n",
    "        Task_CI = 1.96 * np.sqrt((adjust_p(Task_p, group_N) * (1 - adjust_p(Task_p, group_N)))/adjust_n(group_N))\n",
    "\n",
    "        # Save CI in list.\n",
    "        CIs.append([Task_CI,Task_CI,Task_CI])\n",
    "        \n",
    "        \n",
    "        # Print confidence intervals for reference.\n",
    "        print('CONFIDENCE INTERVAL: ' ,item , Task_CI)\n",
    "      \n",
    "    grapher_stacked_CIS(combined_results, graph_columns, task, [], file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n    # List to store CI in\\n    CIs = [] \\n    for item in group_names:\\n        group_N = len(answer_groups[item])\\n        Task_p = combined_results[item + ' (N)']['success']\\n\\n        # CI_95 = 1.96 * SQRT((adjusted_p * (1 - adjusted_p))/adjusted_n)\\n        Task_CI = 1.96 * np.sqrt(Task_p * (1 - Task_p)/group_N)\\n        \\n        # CALCULATE CONFIDENCE INTERVALS\\n        Task_p = (results[t][t + ' (N)']['success'])/N\\n\\n\\n        # Save CI in list.\\n        CIs.append([Task_CI,Task_CI,Task_CI])\\n        \\n        \\n        # Print confidence intervals for reference.\\n        print('CONFIDENCE INTERVAL: ' ,item , Task_CI)\\n      \\n    \\n    grapher_stacked_CIS(combined_results, graph_columns, task, [], file_location)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_task_VS_multiple_N(df, group_q, group_names, task, file_location):\n",
    "    \n",
    "    # Create dataframes of required groups and store in a dict. \n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in group_names:\n",
    "        answer_groups[item] = df[df[group_q].str.contains('(?i)'+item) == True]\n",
    "        answer_groups[item].name = item\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for item in answer_groups:\n",
    "        # Create a list with task value counts.\n",
    "        results[item] = []\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts()))\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts(normalize=True)))\n",
    "\n",
    "        results[item] = pd.concat(results[item], axis=1)\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results, axis=1) \n",
    "    \n",
    "    # Get column names and add 'N' or '%'\n",
    "    column_titles = []\n",
    "    for item in combined_results.columns.get_level_values(0):\n",
    "        column_titles.insert(0, item + ' (N)')\n",
    "        column_titles.insert(0, item + ' (%)')\n",
    "    \n",
    "    # remove duplicate column names from the list\n",
    "    column_titles2 = []\n",
    "    for i in column_titles:\n",
    "        if i not in column_titles2:\n",
    "            column_titles2.insert(0, i)\n",
    "    \n",
    "    graph_columns = []\n",
    "    for i in column_titles2:\n",
    "        if \"(N)\" not in i: \n",
    "            graph_columns.insert(0, i)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    combined_results.columns = column_titles2\n",
    "    combined_results.index.name = task\n",
    "\n",
    "    \n",
    "    display(combined_results)\n",
    "        \n",
    "    # CALCULATE CONFIDENCE INTERVALS\n",
    "\"\"\" \n",
    "    # List to store CI in\n",
    "    CIs = [] \n",
    "    for item in group_names:\n",
    "        group_N = len(answer_groups[item])\n",
    "        Task_p = combined_results[item + ' (N)']['success']\n",
    "\n",
    "        # CI_95 = 1.96 * SQRT((adjusted_p * (1 - adjusted_p))/adjusted_n)\n",
    "        Task_CI = 1.96 * np.sqrt(Task_p * (1 - Task_p)/group_N)\n",
    "        \n",
    "        # CALCULATE CONFIDENCE INTERVALS\n",
    "        Task_p = (results[t][t + ' (N)']['success'])/N\n",
    "\n",
    "\n",
    "        # Save CI in list.\n",
    "        CIs.append([Task_CI,Task_CI,Task_CI])\n",
    "        \n",
    "        \n",
    "        # Print confidence intervals for reference.\n",
    "        print('CONFIDENCE INTERVAL: ' ,item , Task_CI)\n",
    "      \n",
    "    \n",
    "    grapher_stacked_CIS(combined_results, graph_columns, task, [], file_location)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare success rates between 2 or groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create resutls for ATO versus non-ATO per task\n",
    "def breakdown_task_rates(df, task, breakdown, col_names, title, labels, location):\n",
    "    \n",
    "    groups = df[breakdown].unique()\n",
    "    print(groups)\n",
    "    results = []\n",
    "    \n",
    "    results.append(pd.DataFrame(df[task].groupby(df[breakdown]).value_counts()))\n",
    "    results.append(pd.DataFrame(df[task].groupby(df[breakdown]).value_counts(normalize=True)))\n",
    "    results = pd.concat(results, axis=1)\n",
    "    results.index.names = col_names\n",
    "    results.columns = [task+' (N)', task+' (%)']\n",
    "    results = results.sort_index(ascending=False)\n",
    "    \n",
    "    # print\n",
    "    display(results)\n",
    "    \n",
    "    # Calculate 95% CIfor each task results per group\n",
    "    # CI = p_hat +- 1.96 * (sqrt((p_hat*(1-p_hat))/n))\n",
    "    cis=[]\n",
    "    for i in groups:\n",
    "        n = results[task + ' (N)'][i].sum()\n",
    "        p_hat = (results[task + ' (N)'][i,'success'])/n\n",
    "        cis.append(1.96 * (np.sqrt((p_hat * (1-p_hat))/n)))\n",
    "    \n",
    "    grapher_stacked(results, task+' (%)', title, labels, cis, location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare likert results between 2 or groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# break down likert scale questions by dividing up group \n",
    "def breakdown_likert_rates(df, task, breakdown, col_names, title, labels, location):\n",
    "    # Compact standard Likert answers to three-point scale.\n",
    "    cleaned = df[task].replace({'Very dissatisfied': 'Dissatisfied', 'Very satisfied': 'Satisfied',\n",
    "                'Strongly disagree': 'Disagree', 'Strongly agree': 'Agree'}, regex=True)\n",
    "\n",
    "    temp = pd.concat([cleaned, df[breakdown]], axis=1)\n",
    "\n",
    "    results = []\n",
    "    results.append(pd.DataFrame(temp[task].groupby(temp[breakdown]).value_counts()))\n",
    "    results.append(pd.DataFrame(temp[task].groupby(temp[breakdown]).value_counts(normalize=True)))\n",
    "    results = pd.concat(results, axis=1)\n",
    "    results.index.names = col_names\n",
    "    results.columns = [task+' (N)', task+' (%)']\n",
    "    results = results.sort_index(ascending=False)\n",
    "\n",
    "    display(results)\n",
    "\n",
    "    grapher_no_error(results, task+' (%)', title, labels, location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison - Task vs likert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_task_VS_likert(df, task, question, fig_title, labels, location):\n",
    "    \n",
    "    likert_compact = []\n",
    "    \n",
    "    # Compact standard Likert answers to three-point scale and save in a list.\n",
    "    # Create a list with task value counts.\n",
    "    likert_compact.append(pd.DataFrame(df[question].replace(\n",
    "                {'Strongly disagree': 'Disagree', 'Strongly agree': 'Agree'}, regex=True)))\n",
    "    likert_compact.append(pd.DataFrame(df[task]))\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(likert_compact , axis=1) \n",
    "\n",
    "    # Create DataFrame with the results grouped by task completion rate.\n",
    "    combined_results_df = []\n",
    "    \n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts()))\n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts(normalize=True)))\n",
    "    \n",
    "    combined_results_df = pd.concat(combined_results_df, axis=1)\n",
    "    combined_results_df.index.names = [task + ' : Result', question]\n",
    "    combined_results_df.columns = ['(N)', '(%)']\n",
    "    combined_results_df = combined_results_df.sort_index(ascending=False)\n",
    "    \n",
    "    display(combined_results_df)\n",
    "    \n",
    "    # Graph the results\n",
    "    title = fig_title.replace('\"', '')\n",
    "    title = title.replace('?', '')\n",
    "    title = (title[:100] + '...') if len(title) > 100 else title\n",
    "    \n",
    "    # Graph the results\n",
    "    grapher_no_error(combined_results_df, '(%)', title, labels, location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison - Task vs multiple choice - SINGLE answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_task_VS_single(df, task, question, fig_title, labels, file_location):\n",
    "    \n",
    "    likert_compact = []\n",
    "    \n",
    "    # Compact standard Likert answers to three-point scale and save in a list.\n",
    "    # Create a list with task value counts.\n",
    "    likert_compact.append(pd.DataFrame(df[question]))\n",
    "    likert_compact.append(pd.DataFrame(df[task]))\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(likert_compact , axis=1) \n",
    "\n",
    "    # Create DataFrame with the results grouped by task completion rate.\n",
    "    combined_results_df = []\n",
    "    \n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts()))\n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[task]).value_counts(normalize=True)))\n",
    "    \n",
    "    combined_results_df = pd.concat(combined_results_df, axis=1)\n",
    "    combined_results_df.index.names = [task + ' : Result', question]\n",
    "    combined_results_df.columns = ['(N)', '(%)']\n",
    "    combined_results_df = combined_results_df.sort_index(ascending=False)\n",
    "    \n",
    "    display(combined_results_df)\n",
    "    \n",
    "    # Graph the results\n",
    "    title = fig_title.replace('\"', '')\n",
    "    title = title.replace('?', '')\n",
    "    title = (title[:100] + '...') if len(title) > 100 else title\n",
    "    \n",
    "    # Graph the results\n",
    "    grapher_no_error(combined_results_df, '(%)', title, labels, file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison - Likert vs multiple choice - SINGLE answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_likert_VS_single(df, likert, question, graph_type, file_location):\n",
    "    \n",
    "    results_compact = []\n",
    "    \n",
    "    # Compact standard Likert answers to three-point scale and save in a list.\n",
    "    # Create a list with task value counts.\n",
    "    results_compact.append(pd.DataFrame(df[likert].replace({'Strongly disagree': 'Disagree', 'Strongly agree': 'Agree'}, regex=True)))\n",
    "    results_compact.append(pd.DataFrame(df[question]))\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results_compact , axis=1) \n",
    "\n",
    "    # Add grouped results dataframes to a list.\n",
    "    combined_results_df = []\n",
    "    \n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[likert]).value_counts()))\n",
    "    combined_results_df.append(pd.DataFrame(combined_results[question].groupby(combined_results[likert]).value_counts(normalize=True)))\n",
    "    \n",
    "    # Convert list of grouped results dataframes into one DataFrame\n",
    "    combined_results_df = pd.concat(combined_results_df, axis=1)\n",
    "    combined_results_df.index.names = [likert, question]\n",
    "    combined_results_df.columns = ['(N)', '(%)']\n",
    "    combined_results_df = combined_results_df.sort_index(ascending=False)\n",
    "    \n",
    "    display(combined_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likert vs multiple choice - MULTIPLE answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_likert_VS_multiple(df, group_q, group_names, task, file_location):\n",
    "    \n",
    "    temp = []\n",
    "    temp.append(pd.DataFrame(df[task].replace({'Strongly disagree': 'Disagree', 'Strongly agree': 'Agree'}, regex=True)))\n",
    "    temp.append(pd.DataFrame(df[group_q]))\n",
    "    \n",
    "    temp_df = pd.concat(temp, axis=1)\n",
    "    \n",
    "    # Create dataframes of required groups and store in a dict. \n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in group_names:\n",
    "        answer_groups[item] = temp_df[temp_df[group_q].str.contains('(?i)'+item) == True]\n",
    "        answer_groups[item].name = item\n",
    "    \n",
    "    results = {}   \n",
    "    \n",
    "    for item in answer_groups:\n",
    "        \n",
    "        # Create a list with task value counts.\n",
    "        results[item] = []\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts()))\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][task].value_counts(normalize=True)))\n",
    "\n",
    "        results[item] = pd.concat(results[item], axis=1)\n",
    "\n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results, axis=1) \n",
    "    \n",
    "    # Get column names and add 'N' or '%'\n",
    "    column_titles = []\n",
    "    for item in combined_results.columns.get_level_values(0):\n",
    "        column_titles.insert(0, item + ' (N)')\n",
    "        column_titles.insert(0, item + ' (%)')\n",
    "    \n",
    "    # remove duplicate column names from the list\n",
    "    column_titles2 = []\n",
    "    for i in column_titles:\n",
    "        if i not in column_titles2:\n",
    "            column_titles2.insert(0, i)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    combined_results.columns = column_titles2\n",
    "    combined_results.index.name = task\n",
    "      \n",
    "    display(combined_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple choice: SINGLE answer vs MULTIPLE answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_multiple_VS_single(df, group_q, group_names, single_q, file_location):\n",
    "    \n",
    "    # Create dataframes of required groups and store in a dict. \n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in group_names:\n",
    "        answer_groups[item] = df[df[group_q].str.contains('(?i)'+item) == True]\n",
    "        answer_groups[item].name = item\n",
    "    \n",
    "    results = {}\n",
    "    column_titles = []\n",
    "    graph_columns = []\n",
    "    \n",
    "    for item in answer_groups:\n",
    "        # Create a list with single_q value counts.\n",
    "        results[item] = []\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][single_q].value_counts()))\n",
    "        results[item].append(pd.DataFrame(answer_groups[item][single_q].value_counts(normalize=True)))\n",
    "\n",
    "        results[item] = pd.concat(results[item], axis=1)\n",
    "    \n",
    "    # convert the flat list into dataframe columns \n",
    "    combined_results = pd.concat(results, axis=1) \n",
    "    \n",
    "    # Get column names and add 'N' or '%'\n",
    "    column_titles = []\n",
    "    for item in combined_results.columns.get_level_values(0):\n",
    "        column_titles.insert(0, item + ' (N)')\n",
    "        column_titles.insert(0, item + ' (%)')\n",
    "    \n",
    "    # remove duplicate column names from the list\n",
    "    column_titles2 = []\n",
    "    for i in column_titles:\n",
    "        if i not in column_titles2:\n",
    "            column_titles2.insert(0, i)\n",
    "            \n",
    "    graph_columns = []\n",
    "    for i in column_titles2:\n",
    "        if \"(N)\" not in i: \n",
    "            graph_columns.insert(0, i)\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    combined_results.columns = column_titles2\n",
    "    combined_results.index.name = single_q\n",
    "      \n",
    "    display(combined_results)\n",
    "    \n",
    "    grapher_stacked_N(combined_results, graph_columns, single_q, file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display other results (for relevant questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def other_responses(df, question):\n",
    "    responses = []\n",
    "\n",
    "    responses.append(pd.DataFrame(df[question]))\n",
    "    responses = pd.concat(responses, axis=1)\n",
    "    responses = responses[responses[question].notnull()]\n",
    "\n",
    "    print('NUMBER OF RESPONSES: ' , len(responses))\n",
    "    \n",
    "    for item in responses[question]:\n",
    "        display(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of dataframes for dividing multiple answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dataframes of required groups.\n",
    "def define_groups(df, question, groups):\n",
    "    \n",
    "    answer_groups = {}\n",
    "    \n",
    "    for item in groups:\n",
    "        answer_groups[item] = df[df[question].str.contains('(?i)'+item) == True]\n",
    "        answer_groups[item].name = item\n",
    "    \n",
    "    return answer_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
